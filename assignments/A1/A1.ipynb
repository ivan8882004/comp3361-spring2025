{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI4A-T0z5AU6"
      },
      "source": [
        "# Assignment 1\n",
        "You should submit the **UniversityNumber.ipynb** file and your final prediction file **UniversityNumber.test.txt** to moodle. Make sure your code does not use your local files and that the results are reproducible. Before submitting, please **1. clean all outputs and 2. run all cells in your notebook and keep all running logs** so that we can check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.4)\n",
            "Collecting nltk==3.9.1\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "     ---------------------------------------- 1.5/1.5 MB 8.7 MB/s eta 0:00:00\n",
            "Collecting scikit-learn==1.6.1\n",
            "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
            "     --------------------------------------- 11.1/11.1 MB 21.8 MB/s eta 0:00:00\n",
            "Collecting gensim==4.3.3\n",
            "  Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
            "     --------------------------------------- 24.0/24.0 MB 21.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (65.6.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk==3.9.1) (4.65.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk==3.9.1) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk==3.9.1) (2022.7.9)\n",
            "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk==3.9.1) (8.1.7)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "     ------------------------------------- 301.8/301.8 kB 18.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (1.10.1)\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim==4.3.3) (5.2.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk==3.9.1) (0.4.6)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn, nltk, gensim\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 2.2.0\n",
            "    Uninstalling threadpoolctl-2.2.0:\n",
            "      Successfully uninstalled threadpoolctl-2.2.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.1\n",
            "    Uninstalling joblib-1.1.1:\n",
            "      Successfully uninstalled joblib-1.1.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.1\n",
            "    Uninstalling scikit-learn-1.2.1:\n",
            "      Successfully uninstalled scikit-learn-1.2.1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.0\n",
            "    Uninstalling gensim-4.3.0:\n",
            "      Successfully uninstalled gensim-4.3.0\n",
            "Successfully installed gensim-4.3.3 joblib-1.4.2 nltk-3.9.1 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.26.4 nltk==3.9.1 scikit-learn==1.6.1 gensim==4.3.3 setuptools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]\n",
            "✓ numpy version 1.26.4\n",
            "✓ nltk version 3.9.1\n",
            "✓ scikit-learn version 1.6.1\n",
            "✓ gensim version 4.3.3\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup and Validation\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Required package versions\n",
        "required_packages = {\n",
        "    'numpy': '1.26.4',\n",
        "    'nltk': '3.9.1',\n",
        "    'scikit-learn': '1.6.1',\n",
        "    'gensim': '4.3.3'\n",
        "}\n",
        "\n",
        "def validate_environment():\n",
        "    import pkg_resources\n",
        "    installed = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
        "    for package, min_version in required_packages.items():\n",
        "        if package not in installed:\n",
        "            print(f\"❌ {package} not found!\")\n",
        "            return False\n",
        "        if pkg_resources.parse_version(installed[package]) < pkg_resources.parse_version(min_version):\n",
        "            print(f\"❌ {package} version {installed[package]} is below minimum {min_version}\")\n",
        "            return False\n",
        "        print(f\"✓ {package} version {installed[package]}\")\n",
        "    return True\n",
        "\n",
        "assert validate_environment(), \"Please install required packages with correct versions\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEomoMzH5Nf6"
      },
      "source": [
        "# 1 $n$-gram Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsSAtTqt7Q8a"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/lm\n",
        "!wget -O data/lm/train.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/train.txt\n",
        "!wget -O data/lm/dev.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/dev.txt\n",
        "!wget -O data/lm/test.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/lm/test.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ElrINWW7oF7"
      },
      "source": [
        "## 1.1 Building vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instructions:\n",
        "1. Implement a Vocabulary class that:\n",
        "   - Handles OOV words (tokens occurring < 3 times)\n",
        "   - Includes special tokens \\<UNK>, \\<START>, \\<END>\n",
        "   - Provides word2idx and idx2word mappings\n",
        "2. Expected vocabulary size: 24,067 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eawcuVV19kZm"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q-rNT_QL8Dvt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 24067\n"
          ]
        }
      ],
      "source": [
        "# 1.1 Building vocabulary\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from typing import List, Dict\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<UNK>': 0, '<START>': 1, '<END>': 2}\n",
        "        self.idx2word = ['<UNK>', '<START>', '<END>']\n",
        "        self.word_counts = {}\n",
        "        \n",
        "    def build_vocab(self, filepath: str, min_freq: int = 3) -> None:\n",
        "        \"\"\"Build vocabulary from training file\n",
        "        \n",
        "        Args:\n",
        "            filepath: Path to training file\n",
        "            min_freq: Minimum frequency threshold for words\n",
        "        \"\"\"\n",
        "        \n",
        "\n",
        "        words = nltk.tokenize.word_tokenize(open(filepath).read().lower())\n",
        "        self.word_counts = Counter(words)\n",
        "        \n",
        "        for word, count in self.word_counts.items():\n",
        "            if count >= min_freq:\n",
        "                self.word2idx[word] = len(self.word2idx)\n",
        "                self.idx2word.append(word)\n",
        "        \n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.word2idx)\n",
        "    \n",
        "    def get_id(self, word: str) -> int:\n",
        "        \"\"\"Get ID for word (returns UNK if not in vocab)\"\"\"\n",
        "\n",
        "        if word in self.word2idx:\n",
        "            return self.word2idx[word]\n",
        "        else:\n",
        "            return self.word2idx['<UNK>']\n",
        "    \n",
        "    def get_word(self, idx: int) -> str:\n",
        "        \"\"\"Get word for ID\"\"\"\n",
        "\n",
        "        return self.idx2word[idx]\n",
        "\n",
        "# Test vocabulary\n",
        "vocab = Vocabulary()\n",
        "vocab.build_vocab('data/lm/train.txt')\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "assert len(vocab) == 24067, \"Vocabulary size should be 24,067\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7oBATsX8uHb"
      },
      "source": [
        "### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU6VpAkS9odh"
      },
      "source": [
        "Discuss the number of parameters in n-gram models here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ2BGUig8TqH"
      },
      "source": [
        "## 1.2 $n$-gram Language Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instructions:\n",
        "1. Implement an n-gram language model that:\n",
        "   - Counts n-grams from training data\n",
        "   - Computes probabilities\n",
        "   - Calculates perplexity\n",
        "2. Test with both unigram and bigram models\n",
        "3. Report perplexity on train and dev sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeyANMPe9ad_"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ACSfNZGE8Yw2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Unigram model\n",
            "Perplexity on train: 36743349108360492568306221912112310642028820658388992.00\n",
            "Perplexity on dev: 13410776981611227004933209290437282562544059864317952.00\n",
            "\n",
            "\n",
            "Testing Bigram model\n",
            "Perplexity on train: 91658798081712150559623617708032000.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17668\\182068893.py:63: RuntimeWarning: divide by zero encountered in log\n",
            "  L += np.log(self.get_prob(word, context))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity on dev: inf\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "\n",
        "class LanguageModel:\n",
        "    def __init__(self, vocab: Vocabulary, n: int):\n",
        "        \"\"\"Initialize n-gram language model\n",
        "        \n",
        "        Args:\n",
        "            vocab: Vocabulary object\n",
        "            n: Order of n-gram model\n",
        "        \"\"\"\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(int)\n",
        "        self.context_counts = defaultdict(int)\n",
        "        \n",
        "    def get_ngrams(self, tokens: List[str], n: int) -> List[Tuple[str]]:\n",
        "        \"\"\"Extract n-grams from token sequence\"\"\"\n",
        "\n",
        "        n_grams = []\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            n_grams.append(tuple(tokens[i:i+n]))\n",
        "        return n_grams\n",
        "        \n",
        "    def train(self, filepath: str) -> None:\n",
        "        \"\"\"Train n-gram language model\"\"\"\n",
        "\n",
        "        tokens = []\n",
        "        with open(filepath) as f:\n",
        "            for line in f:\n",
        "                tokens_in_line = nltk.tokenize.word_tokenize(line.lower())\n",
        "                tokens_in_line = [token if token in self.vocab.idx2word else '<UNK>' for token in tokens_in_line]\n",
        "                tokens.extend((self.n - 1) * ['<START>'] + tokens_in_line + (self.n - 1) * ['<END>'])\n",
        "        n_grams = self.get_ngrams(tokens, self.n)\n",
        "        self.ngram_counts = Counter(n_grams)\n",
        "        context = self.get_ngrams(tokens, self.n - 1)\n",
        "        self.context_counts = Counter(context)\n",
        "\n",
        "\n",
        "                \n",
        "    def get_prob(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"Get probability of word given context\"\"\"\n",
        "\n",
        "        return self.ngram_counts[context + (word,)]  / self.context_counts[context]  \n",
        "    \n",
        "    def perplexity(self, filepath: str) -> float:\n",
        "        \"\"\"Calculate perplexity on given text\"\"\"\n",
        "\n",
        "        L = 0\n",
        "        line_counter = 0\n",
        "        with open(filepath) as f:\n",
        "            for line in f:\n",
        "                line_counter += 1\n",
        "                tokens = []\n",
        "                tokens_in_line = nltk.tokenize.word_tokenize(line.lower())\n",
        "                tokens_in_line = [token if token in self.vocab.idx2word else '<UNK>' for token in tokens_in_line]\n",
        "                tokens.extend((self.n - 1) * ['<START>'] + tokens_in_line + (self.n - 1) * ['<END>'])\n",
        "                for i in range(len(tokens) - self.n + 1):\n",
        "                    context = tuple(tokens[i:i+self.n-1])\n",
        "                    word = tokens[i+self.n-1]\n",
        "                    L += np.log(self.get_prob(word, context))\n",
        "        L /= line_counter\n",
        "        return 2 ** (-L)\n",
        "                \n",
        "\n",
        "# Test language model\n",
        "print(\"Testing Unigram model\")\n",
        "lm = LanguageModel(vocab, n=1)\n",
        "lm.train('data/lm/train.txt')\n",
        "train_perplexity = lm.perplexity('data/lm/train.txt')\n",
        "print(f\"Perplexity on train: {train_perplexity:.2f}\")\n",
        "assert train_perplexity > 0, \"Perplexity should be positive\"\n",
        "dev_perplexity = lm.perplexity('data/lm/dev.txt')\n",
        "print(f\"Perplexity on dev: {dev_perplexity:.2f}\")\n",
        "assert dev_perplexity > 0, \"Perplexity should be positive\"\n",
        "print('\\n')\n",
        "\n",
        "print(\"Testing Bigram model\")\n",
        "lm = LanguageModel(vocab, n=2)\n",
        "lm.train('data/lm/train.txt')\n",
        "train_perplexity = lm.perplexity('data/lm/train.txt')\n",
        "print(f\"Perplexity on train: {train_perplexity:.2f}\")\n",
        "assert train_perplexity > 0, \"Perplexity should be positive\"\n",
        "dev_perplexity = lm.perplexity('data/lm/dev.txt')\n",
        "print(f\"Perplexity on dev: {dev_perplexity:.2f}\")\n",
        "assert dev_perplexity > 0, \"Perplexity should be positive\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRWC56a19TbY"
      },
      "source": [
        "### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM4gcgL--Ylh"
      },
      "source": [
        "Compare unigram and bigram model performance here\n",
        "\n",
        "Answer:\n",
        "\n",
        "The unigram model assigns probabilities purely based on word frequencies. If the training data has a large vocabulary with many rare words, probabilities for individual words become extremely small.\n",
        "Numerical Instability: Multiplying many small probabilities (or summing log-probabilities) leads to underflow/overflow.\n",
        "\n",
        "\n",
        "As we have not introduced smoothing, some context words in dev set do not exist in the model's context_counts dictionary, leading to \"divide by zero\" warning.\n",
        "For bigrams in the dev set that never appeared in training,  𝑝(𝑤∣𝑐𝑜𝑛𝑡𝑒𝑥𝑡) = 0/0 -> log(0) = −inf -> 2^(-(-inf)) = inf\n",
        "So perplexity on dev test becomes inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuLL8CH1Ua-3"
      },
      "source": [
        "## 1.3 Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7mWQhaCUixZ"
      },
      "source": [
        "### 1.3.1 Add-one (Laplace) smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbbHxLDmVrz6"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "93_yLu9dVr0C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Add-one perplexity on dev: 20445536530650362214269891051222707355811898949829518163968.00\n"
          ]
        }
      ],
      "source": [
        "class AddOneLanguageModel(LanguageModel):\n",
        "    def get_prob(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"Get smoothed probability using add-one smoothing\"\"\"\n",
        "        return (self.ngram_counts[context + (word,)] + 1) / (self.context_counts[context] + len(self.vocab)) \n",
        "\n",
        "# Test add-one smoothing\n",
        "add_one_lm = AddOneLanguageModel(vocab, n=2)\n",
        "add_one_lm.train('data/lm/train.txt')\n",
        "print(f\"Add-one perplexity on dev: {add_one_lm.perplexity('data/lm/dev.txt'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y1WOQtsVr0D"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTknh9pRVr0D"
      },
      "source": [
        "Analyze how add-one smoothing affects the model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTC0qJE8VVha"
      },
      "source": [
        "#### 1.3.2 Add-k smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instructions:\n",
        "1. Implement add-k smoothing with configurable k\n",
        "2. Try k values: 0.1, 0.5, 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3itGMOOVuNg"
      },
      "source": [
        "##### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jhcuJWo7VuNg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Add-0.1 perplexity on dev: 3715008495159369346337322801386625080596916040892416.00\n",
            "Add-0.5 perplexity on dev: 98912615932611895189546270179767627933763998264149934080.00\n",
            "Add-1.0 perplexity on dev: 20445536530650362214269891051222707355811898949829518163968.00\n"
          ]
        }
      ],
      "source": [
        "class AddKLanguageModel(LanguageModel):\n",
        "    def __init__(self, vocab: Vocabulary, n: int, k: float):\n",
        "        super().__init__(vocab, n)\n",
        "        self.k = k\n",
        "        \n",
        "    def get_prob(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"Get smoothed probability using add-k smoothing\"\"\"\n",
        "        return (self.ngram_counts[context + (word,)] + self.k) / (self.context_counts[context] + self.k * len(self.vocab))\n",
        "\n",
        "# Test add-k smoothing with different k values\n",
        "k_values = [0.1, 0.5, 1.0]\n",
        "for k in k_values:\n",
        "    add_k_lm = AddKLanguageModel(vocab, n=2, k=k)\n",
        "    add_k_lm.train('data/lm/train.txt')\n",
        "    print(f\"Add-{k} perplexity on dev: {add_k_lm.perplexity('data/lm/dev.txt'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzpU_p6CVuNg"
      },
      "source": [
        "##### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIOUpNXYVuNh"
      },
      "source": [
        "Compare performance with different k values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJFWxsN-Uj0Y"
      },
      "source": [
        "### 1.3.3 Linear Interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instructions:\n",
        "1. Implement linear interpolation of unigram, bigram, and trigram models\n",
        "2. Initial lambdas: [0.1, 0.3, 0.6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk11EpboWVCH"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K4N_XuN6WVCQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interpolated perplexity on dev: 85412133823217001061792131807045925146780616670404438911629635304275574784.00\n"
          ]
        }
      ],
      "source": [
        "class InterpolatedLanguageModel:\n",
        "    def __init__(self, vocab: Vocabulary, lambdas: List[float]):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vocab: Vocabulary object\n",
        "            lambdas: List of interpolation weights (should sum to 1)\n",
        "        \"\"\"\n",
        "        assert abs(sum(lambdas) - 1.0) < 1e-6, \"Lambdas must sum to 1\"\n",
        "        self.vocab = vocab\n",
        "        self.lambdas = lambdas\n",
        "        self.models = [AddOneLanguageModel(vocab, n=i+1) for i in range(len(lambdas))]\n",
        "        \n",
        "    def train(self, filepath: str) -> None:\n",
        "        \"\"\"Train all n-gram models\"\"\"\n",
        "        for model in self.models:\n",
        "            model.train(filepath)\n",
        "            \n",
        "    def get_prob(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"Get interpolated probability\"\"\"\n",
        "        return sum(lambda_ * model.get_prob(word, context) for lambda_, model in zip(self.lambdas, self.models))\n",
        "    \n",
        "    def perplexity(self, filepath: str) -> float:\n",
        "        \"\"\"Calculate perplexity using interpolated probabilities\"\"\"\n",
        "        \n",
        "        L = 0\n",
        "        line_counter = 0\n",
        "        with open(filepath) as f:\n",
        "            for line in f:\n",
        "                line_counter += 1\n",
        "                tokens = []\n",
        "                tokens_in_line = nltk.tokenize.word_tokenize(line.lower())\n",
        "                tokens_in_line = [token if token in self.vocab.idx2word else '<UNK>' for token in tokens_in_line]\n",
        "                tokens.extend((len(self.lambdas) - 1) * ['<START>'] + tokens_in_line + (len(self.lambdas) - 1) * ['<END>'])\n",
        "                for i in range(len(tokens) - len(self.lambdas) + 1):\n",
        "                    context = tuple(tokens[i:i+len(self.lambdas)-1])\n",
        "                    word = tokens[i+len(self.lambdas)-1]\n",
        "                    L += np.log(self.get_prob(word, context))\n",
        "        L /= line_counter\n",
        "        return 2 ** (-L)\n",
        "    \n",
        "    \n",
        "# Test interpolated model\n",
        "lambdas = [0.1, 0.3, 0.6]  # Example weights for unigram, bigram, trigram\n",
        "interpolated_lm = InterpolatedLanguageModel(vocab, lambdas)\n",
        "interpolated_lm.train('data/lm/train.txt')\n",
        "print(f\"Interpolated perplexity on dev: {interpolated_lm.perplexity('data/lm/dev.txt'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh8v2P36WVCQ"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGkf6IV0WVCQ"
      },
      "source": [
        "Analyze the effectiveness of interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvgTZcNFVato"
      },
      "source": [
        "##### 1.3.4 Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKnXu98hWcfu"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKo4ZLASWcfu"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2 Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_embedding_model():\n",
        "    \"\"\" Load GloVe Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 400000 embeddings, each lengh 50\n",
        "    \"\"\"\n",
        "    import gensim.downloader as api\n",
        "    wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
        "    print(\"Loaded vocab size %i\" % len(list(wv_from_bin.index_to_key)))\n",
        "    return wv_from_bin\n",
        "\n",
        "wv_from_bin = load_embedding_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Find most similar word\n",
        "### Instructions:\n",
        "1. Implement function to find similar words using cosine similarity\n",
        "2. Expected similarity scores should be between 0 and 1\n",
        "3. Return top 3 similar words for each query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_most_similar(word: str, wv_from_bin) -> List[Tuple[str, float]]:\n",
        "    \"\"\"Find most similar words using cosine similarity\n",
        "    \n",
        "    Args:\n",
        "        word: Query word\n",
        "        wv_from_bin: Loaded word vectors\n",
        "        \n",
        "    Returns:\n",
        "        List of (word, similarity) tuples\n",
        "    \"\"\"\n",
        "    # TODO: Implement similarity search\n",
        "    pass\n",
        "\n",
        "test_words = [\n",
        "    'ubiquitous',\n",
        "    'serendipity',\n",
        "    'melancholy',\n",
        "    'paradox',\n",
        "    'ethereal',\n",
        "    'cacophony'\n",
        "]\n",
        "for word in test_words:\n",
        "    similar_words = find_most_similar(word, wv_from_bin)\n",
        "    print(f\"\\nMost similar to '{word}':\")\n",
        "    for similar_word, similarity in similar_words:\n",
        "        print(f\"{similar_word}: {similarity:.3f}\")\n",
        "        assert 0 <= similarity <= 1, f\"Invalid similarity score: {similarity}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Finding Analogies\n",
        "Use vector addition and subtraction to compute target vectors for the analogies below. After computing each target vector, find the top three candidates by cosine similarity. Report the candidates and their similarities to the target vector.\n",
        "\n",
        "- dog : puppy :: cat : ?:\n",
        "- speak : speaker :: sing : ?:\n",
        "- France : French :: England : ?:\n",
        "- France : wine :: England : ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_analogy(a: str, b: str, c: str, wv_from_bin) -> List[Tuple[str, float]]:\n",
        "    \"\"\"Find word analogies using vector arithmetic\n",
        "    \n",
        "    Args:\n",
        "        a, b, c: Words for analogy a:b :: c:?\n",
        "        wv_from_bin: Loaded word vectors\n",
        "        \n",
        "    Returns:\n",
        "        List of (word, similarity) tuples\n",
        "    \"\"\"\n",
        "    # TODO: Implement analogy finding\n",
        "    pass\n",
        "\n",
        "# Test analogies\n",
        "analogies = [\n",
        "    ('king', 'queen', 'man'), \n",
        "    ('paris', 'france', 'rome'),\n",
        "    ('france', 'french', 'germany'),\n",
        "    ('london', 'england', 'paris'),\n",
        "    ('cat', 'kitten', 'dog'),\n",
        "    ('rich', 'poor', 'strong')\n",
        "]\n",
        "for a, b, c in analogies:\n",
        "    print(f\"\\nAnalogy: {a}:{b} :: {c}:?\")\n",
        "    results = find_analogy(a, b, c, wv_from_bin)\n",
        "    for word, similarity in results:\n",
        "        print(f\"{word}: {similarity:.3f}\")\n",
        "        assert 0 <= similarity <= 1, f\"Invalid similarity score: {similarity}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3 Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p data/classification\n",
        "!wget -O data/classification/train.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/classification/train.txt\n",
        "!wget -O data/classification/dev.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/classification/dev.txt\n",
        "!wget -O data/classification/test-blind.txt https://raw.githubusercontent.com/ranpox/comp3361-spring2025/main/assignments/A1/data/classification/test-blind.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "def load_data(filepath: str) -> Tuple[List[str], List[int]]:\n",
        "    \"\"\"Load text and labels from file\"\"\"\n",
        "    texts, labels = [], []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            label, text = line.strip().split('\\t')\n",
        "            texts.append(text)\n",
        "            labels.append(int(label))\n",
        "    return texts, labels\n",
        "\n",
        "class SentimentClassifier:\n",
        "    def __init__(self, feature_type: str = 'unigram'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_type: One of 'unigram', 'bigram', or 'glove'\n",
        "        \"\"\"\n",
        "        self.feature_type = feature_type\n",
        "        self.vectorizer = None\n",
        "        self.classifier = LogisticRegression(random_state=42)\n",
        "        \n",
        "    def extract_features(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Extract features based on feature_type\"\"\"\n",
        "        if self.feature_type == 'unigram':\n",
        "            # TODO: Implement unigram feature extraction\n",
        "            pass\n",
        "        elif self.feature_type == 'bigram':\n",
        "            # TODO: Implement bigram feature extraction \n",
        "            pass\n",
        "        elif self.feature_type == 'glove':\n",
        "            # TODO: Implement glove feature extraction\n",
        "            # Average word vectors for each text\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid feature type: {self.feature_type}\")\n",
        "            \n",
        "    def train(self, train_texts: List[str], train_labels: List[int]) -> None:\n",
        "        \"\"\"Train sentiment classifier\"\"\"\n",
        "        # TODO: Implement training\n",
        "        pass\n",
        "        \n",
        "    def predict(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Predict sentiment labels\"\"\"\n",
        "        # TODO: Implement prediction\n",
        "        pass\n",
        "    \n",
        "    def evaluate(self, texts: List[str], labels: List[int]) -> Dict:\n",
        "        \"\"\"Evaluate classifier performance\"\"\"\n",
        "        predictions = self.predict(texts)\n",
        "        return classification_report(labels, predictions, output_dict=True)\n",
        "\n",
        "# Train and evaluate models with different features\n",
        "train_texts, train_labels = load_data('data/classification/train.txt')\n",
        "dev_texts, dev_labels = load_data('data/classification/dev.txt')\n",
        "\n",
        "results = {}\n",
        "for feature_type in ['unigram', 'bigram', 'glove']:\n",
        "    classifier = SentimentClassifier(feature_type)\n",
        "    classifier.train(train_texts, train_labels)\n",
        "    results[feature_type] = classifier.evaluate(dev_texts, dev_labels)\n",
        "    \n",
        "# Print results\n",
        "for feature_type, metrics in results.items():\n",
        "    print(f\"\\n{feature_type.upper()} Results:\")\n",
        "    print(f\"Precision: {metrics['weighted avg']['precision']:.3f}\")\n",
        "    print(f\"Recall: {metrics['weighted avg']['recall']:.3f}\")\n",
        "    print(f\"F1-score: {metrics['weighted avg']['f1-score']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the performance of three types of features on dev set. Report the weighted average precision, recall and F1-score for each feature set.\n",
        "\n",
        "| Feature | precision | recall | F1-score |\n",
        "| ----------- | --------- | ------ | -------- |\n",
        "| unigram     |           |        |          |\n",
        "| bigram      |           |        |          |\n",
        "| GloVe       |           |        |          |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Better Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
